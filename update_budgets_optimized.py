#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
å„ªåŒ–ç‰ˆï¼šæ‰¹é‡æ›´æ–°é¤å»³é ç®—ï¼ˆä½¿ç”¨ä¸¦ç™¼è™•ç†å’Œæ­£å‰‡è¡¨é”å¼ï¼‰
"""

import json
import requests
import re
import time
from concurrent.futures import ThreadPoolExecutor, as_completed
from typing import Optional, Dict, List
from requests.adapters import HTTPAdapter
from urllib3.util.retry import Retry

# priceRangeId å°æ‡‰é—œä¿‚
PRICE_RANGE_MAP = {
    '1': '100ä»¥ä¸‹',      # 100å…ƒä»¥å…§
    '2': '100-200',      # 100-200å…ƒ
    '3': '200-500',      # 200-500å…ƒ
    '4': '500-1000',     # 500-1000å…ƒ
    '5': '1000-1500',    # 1000-1500å…ƒ
    '6': '1500ä»¥ä¸Š'      # 1500å…ƒä»¥ä¸Š
}

def create_session() -> requests.Session:
    """å‰µå»ºå¸¶æœ‰é‡è©¦æ©Ÿåˆ¶çš„ Session"""
    session = requests.Session()
    
    # è¨­ç½®é‡è©¦ç­–ç•¥
    retry_strategy = Retry(
        total=3,
        backoff_factor=0.3,
        status_forcelist=[429, 500, 502, 503, 504],
    )
    adapter = HTTPAdapter(max_retries=retry_strategy)
    session.mount("http://", adapter)
    session.mount("https://", adapter)
    
    # è¨­ç½® headers
    session.headers.update({
        'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36',
        'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8',
        'Accept-Language': 'zh-TW,zh;q=0.9',
    })
    
    return session

def scrape_budget_fast(session: requests.Session, url: str) -> Optional[str]:
    """
    å¿«é€Ÿçˆ¬å–é ç®—è³‡è¨Šï¼ˆä½¿ç”¨æ­£å‰‡è¡¨é”å¼ï¼‰
    
    Args:
        session: requests Session å°è±¡
        url: OpenRice é¤å»³é é¢ URL
        
    Returns:
        é ç®—å­—ä¸²ï¼Œä¾‹å¦‚ "200-500" æˆ– None
    """
    try:
        response = session.get(url, timeout=15)
        response.raise_for_status()
        
        # ä½¿ç”¨æ­£å‰‡è¡¨é”å¼ç›´æ¥æŸ¥æ‰¾ priceRangeIdï¼ˆä¸è§£ææ•´å€‹ HTMLï¼‰
        # å…ˆå˜—è©¦åœ¨ pdhs-filter-tags-section å€åŸŸå…§æŸ¥æ‰¾
        section_match = re.search(
            r'<div[^>]*class=["\']pdhs-filter-tags-section["\'][^>]*>(.*?)</div>',
            response.text,
            re.DOTALL | re.IGNORECASE
        )
        
        if section_match:
            # åœ¨è©² section ä¸­æŸ¥æ‰¾ priceRangeId
            section_html = section_match.group(1)
            price_match = re.search(r'priceRangeId=(\d+)', section_html)
        else:
            # å¦‚æœæ‰¾ä¸åˆ° sectionï¼Œç›´æ¥åœ¨å…¨æ–‡ä¸­æŸ¥æ‰¾ï¼ˆå‚™ç”¨æ–¹æ¡ˆï¼‰
            price_match = re.search(r'priceRangeId=(\d+)', response.text)
        
        if price_match:
            price_range_id = price_match.group(1)
            budget = PRICE_RANGE_MAP.get(price_range_id)
            return budget
        
        return None
        
    except Exception as e:
        return None

def process_restaurant(session: requests.Session, restaurant: Dict, index: int, total: int) -> Dict:
    """
    è™•ç†å–®å€‹é¤å»³
    
    Returns:
        {
            'index': int,
            'name': str,
            'success': bool,
            'budget': str or None,
            'error': str or None
        }
    """
    name = restaurant.get('name', 'æœªçŸ¥é¤å»³')
    url = restaurant.get('url', '')
    
    result = {
        'index': index,
        'name': name,
        'success': False,
        'budget': None,
        'error': None
    }
    
    if not url:
        result['error'] = 'ç„¡ URL'
        return result
    
    budget = scrape_budget_fast(session, url)
    
    if budget:
        result['success'] = True
        result['budget'] = budget
    else:
        result['error'] = 'ç„¡æ³•ç²å–é ç®—'
    
    return result

def update_budgets_batch(
    json_file: str,
    batch_size: int = 50,
    start_index: int = 0,
    max_workers: int = 10,
    delay: float = 0.3
):
    """
    æ‰¹é‡æ›´æ–°é¤å»³é ç®—ï¼ˆå„ªåŒ–ç‰ˆï¼šä¸¦ç™¼è™•ç†ï¼‰
    
    Args:
        json_file: JSON æª”æ¡ˆè·¯å¾‘
        batch_size: æ¯æ‰¹è™•ç†çš„é¤å»³æ•¸é‡
        start_index: å¾ç¬¬å¹¾é–“é–‹å§‹è™•ç†
        max_workers: ä¸¦ç™¼ç·šç¨‹æ•¸ï¼ˆå»ºè­° 5-10ï¼‰
        delay: æ¯å€‹è«‹æ±‚ä¹‹é–“çš„å»¶é²ï¼ˆç§’ï¼‰
    """
    print("=" * 80)
    print("é–‹å§‹æ‰¹é‡æ›´æ–°é¤å»³é ç®—ï¼ˆå„ªåŒ–ç‰ˆï¼‰")
    print("=" * 80)
    
    # è¼‰å…¥è³‡æ–™åº«
    with open(json_file, 'r', encoding='utf-8') as f:
        data = json.load(f)
    
    restaurants = data['restaurants']
    
    # æ‰¾å‡ºæ‰€æœ‰éœ€è¦æ›´æ–°é ç®—çš„é¤å»³ï¼ˆå¯ä»¥é¸æ“‡åªæ›´æ–° null çš„ï¼Œæˆ–å…¨éƒ¨æ›´æ–°ï¼‰
    # é€™è£¡é¸æ“‡æ›´æ–°æ‰€æœ‰é¤å»³ï¼ˆå¯ä»¥æ ¹æ“šéœ€æ±‚ä¿®æ”¹ï¼‰
    restaurants_to_update = [(i, r) for i, r in enumerate(restaurants) if r.get('url')]
    
    print(f"\nç¸½é¤å»³æ•¸ï¼š{len(restaurants)} é–“")
    print(f"æœ‰ URL çš„é¤å»³ï¼š{len(restaurants_to_update)} é–“")
    print(f"æœ¬æ¬¡è™•ç†ï¼šå¾ç¬¬ {start_index + 1} é–“é–‹å§‹ï¼Œè™•ç† {batch_size} é–“")
    print(f"ä¸¦ç™¼ç·šç¨‹æ•¸ï¼š{max_workers}")
    print(f"è«‹æ±‚å»¶é²ï¼š{delay} ç§’\n")
    
    # è™•ç†æŒ‡å®šç¯„åœçš„é¤å»³
    if start_index >= len(restaurants_to_update):
        print(f"âš ï¸  èµ·å§‹ç´¢å¼• {start_index} è¶…å‡ºç¯„åœï¼ˆç¸½å…± {len(restaurants_to_update)} é–“é¤å»³ï¼‰")
        return
    
    end_index = min(start_index + batch_size, len(restaurants_to_update))
    restaurants_to_process = restaurants_to_update[start_index:end_index]
    
    # å‰µå»º Sessionï¼ˆæ‰€æœ‰ç·šç¨‹å…±äº«ï¼‰
    session = create_session()
    
    updated_count = 0
    failed_count = 0
    
    print(f"é–‹å§‹è™•ç† {len(restaurants_to_process)} é–“é¤å»³...\n")
    start_time = time.time()
    
    # ä½¿ç”¨ç·šç¨‹æ± ä¸¦ç™¼è™•ç†
    with ThreadPoolExecutor(max_workers=max_workers) as executor:
        # æäº¤æ‰€æœ‰ä»»å‹™
        future_to_restaurant = {
            executor.submit(
                process_restaurant,
                session,
                restaurant,
                start_index + idx + 1,
                len(restaurants_to_update)
            ): (original_idx, restaurant)
            for idx, (original_idx, restaurant) in enumerate(restaurants_to_process)
        }
        
        # è™•ç†å®Œæˆçš„ä»»å‹™
        completed = 0
        for future in as_completed(future_to_restaurant):
            original_idx, restaurant = future_to_restaurant[future]
            completed += 1
            
            try:
                result = future.result()
                
                if result['success']:
                    restaurants[original_idx]['budget'] = result['budget']
                    updated_count += 1
                    print(f"[{result['index']}/{len(restaurants_to_update)}] {result['name'][:50]} ... âœ… {result['budget']}")
                else:
                    failed_count += 1
                    print(f"[{result['index']}/{len(restaurants_to_update)}] {result['name'][:50]} ... âŒ {result['error']}")
                
                # æ¯è™•ç† 10 é–“ä¿å­˜ä¸€æ¬¡
                if completed % 10 == 0:
                    with open(json_file, 'w', encoding='utf-8') as f:
                        json.dump(data, f, ensure_ascii=False, indent=2)
                    elapsed = time.time() - start_time
                    rate = completed / elapsed if elapsed > 0 else 0
                    print(f"  ğŸ’¾ å·²ä¿å­˜é€²åº¦ï¼ˆ{completed}/{len(restaurants_to_process)}ï¼Œé€Ÿåº¦ï¼š{rate:.1f} é–“/ç§’ï¼‰")
                
                # æ§åˆ¶è«‹æ±‚é€Ÿç‡ï¼ˆé¿å…éå¿«ï¼‰
                time.sleep(delay)
                
            except Exception as e:
                failed_count += 1
                print(f"[{completed}/{len(restaurants_to_process)}] è™•ç†éŒ¯èª¤ï¼š{str(e)}")
    
    # æœ€çµ‚ä¿å­˜
    print("\n" + "=" * 80)
    print("ä¿å­˜æ›´æ–°å¾Œçš„è³‡æ–™åº«...")
    with open(json_file, 'w', encoding='utf-8') as f:
        json.dump(data, f, ensure_ascii=False, indent=2)
    
    elapsed_time = time.time() - start_time
    
    print("\n" + "=" * 80)
    print("âœ… æœ¬æ‰¹æ¬¡è™•ç†å®Œæˆï¼")
    print(f"\nçµ±è¨ˆï¼š")
    print(f"  è™•ç†æ•¸é‡ï¼š{len(restaurants_to_process)} é–“")
    print(f"  æˆåŠŸæ›´æ–°ï¼š{updated_count} é–“")
    print(f"  å¤±æ•—ï¼š{failed_count} é–“")
    if len(restaurants_to_process) > 0:
        print(f"  æˆåŠŸç‡ï¼š{updated_count/len(restaurants_to_process)*100:.1f}%")
    print(f"  ç¸½è€—æ™‚ï¼š{elapsed_time:.1f} ç§’")
    print(f"  å¹³å‡é€Ÿåº¦ï¼š{len(restaurants_to_process)/elapsed_time:.1f} é–“/ç§’")
    print("=" * 80)
    
    # æç¤ºä¸‹ä¸€æ‰¹æ¬¡
    if end_index < len(restaurants_to_update):
        print(f"\nğŸ’¡ æç¤ºï¼šé‚„æœ‰ {len(restaurants_to_update) - end_index} é–“é¤å»³å¾…è™•ç†")
        print(f"   ä¸‹æ¬¡é‹è¡Œï¼špython3 update_budgets_optimized.py --start {end_index}")

if __name__ == "__main__":
    import argparse
    
    parser = argparse.ArgumentParser(description="å„ªåŒ–ç‰ˆæ‰¹é‡æ›´æ–°é¤å»³é ç®—")
    parser.add_argument('--batch-size', type=int, default=50, help='æ¯æ‰¹è™•ç†çš„é¤å»³æ•¸é‡ï¼ˆé è¨­ï¼š50ï¼‰')
    parser.add_argument('--start', type=int, default=0, help='å¾ç¬¬å¹¾é–“é–‹å§‹è™•ç†ï¼ˆé è¨­ï¼š0ï¼‰')
    parser.add_argument('--workers', type=int, default=10, help='ä¸¦ç™¼ç·šç¨‹æ•¸ï¼ˆé è¨­ï¼š10ï¼‰')
    parser.add_argument('--delay', type=float, default=0.3, help='æ¯å€‹è«‹æ±‚ä¹‹é–“çš„å»¶é²ï¼ˆç§’ï¼Œé è¨­ï¼š0.3ï¼‰')
    
    args = parser.parse_args()
    
    update_budgets_batch(
        'restaurants_database.json',
        batch_size=args.batch_size,
        start_index=args.start,
        max_workers=args.workers,
        delay=args.delay
    )
